{"name":"Pyscape","tagline":"A script to grab data from the Mozscape API. Requires Python &ge; 3.2.","body":"## Disclaimer\r\n\r\n_I am not representing SEOmoz through my development of this tool; it\r\nis completely independent. Neither SEOmoz nor me should be held accountable\r\nif this doesn't work as expected._\r\n\r\nThat said, I hope you find this useful!\r\n\r\n## Getting started\r\n\r\nTo use Pyscape you will need:\r\n\r\n1. A Python installation &ge; 3.2.\r\n2. A set of [Mozscape API \r\n   credentials](http://apiwiki.seomoz.org/create-and-manage-your-account), \r\n   free or paid. It's a phenomenal service they offer, so \r\n   I recommend you try it out if you aren't familiar.\r\n\r\nPut your keys in a file called `keys.json` in the same directory \r\nas the script. The structure of this file should be:\r\n\r\n```\r\n{\r\n    \"access-id\": \"your-id-here\",\r\n    \"secret-key\": \"your-key-here\",\r\n    \"level\": \"access-level\"\r\n}\r\n```\r\n\r\n...where `access-level` is one of `free`, `pro`, or `full` \r\ndepending on the [level of rate \r\nlimiting](http://apiwiki.seomoz.org/rate-limiting) you need.\r\n\r\n## Usage\r\n\r\n\r\n```\r\nusage: pyscape.py [-h] [-d | -s | -p] [-o | -m | -f | -t] [-j | -c]\r\n                  {metrics,bulk-metrics,anchor,top,links,ose-style} source\r\n                  dest\r\n\r\nInterface with the Mozscape API to provide link metrics\r\n\r\npositional arguments:\r\n  {metrics,bulk-metrics,anchor,top,links,ose-style}\r\n                        select operating mode\r\n  source                specify a URL or text file as appropriate\r\n  dest                  specify an output file\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n  -d, --domain-mode     interpret input URL(s) as domains only\r\n  -s, --subdomain-mode  interpret input URL(s) as subdomains only\r\n  -p, --page-mode       interpret input URL(s) as individual pages; default\r\n  -o, --one-page        in link mode, return one page per linking domain\r\n  -m, --many-pages      in link mode, return many pages per linking domain;\r\n                        default\r\n  -f, --phrase          in anchor mode, return phrase matches\r\n  -t, --term            in anchor mode, return term matches; default\r\n  -j, --json            write data in JSON format\r\n  -c, --csv             write data in CSV format; default\r\n```\r\n\r\n### Examples\r\n\r\nNotes:\r\n\r\n1. URLs must not be preceded by http:// or https://. Currently there is no built in filtering for this.\r\n2. On Windows you'll probably have to prepend \"python\" or \"python3\" to all of the following calls.\r\n\r\n```\r\npyscape.py links www.example.com links.csv -d -m\r\n# export a CSV with all available links to example.com\r\n\r\npyscape.py ose-style www.example.com report.csv -d -o\r\n# export a CSV matching OSE's format with all domains\r\n# linking to the target domain\r\n\r\npyscape.py bulk-metrics urls.txt output.csv -p\r\n# export page level metrics for a list of urls\r\n\r\npyscape.py bulk-metrics urls.txt output.csv -d\r\n# export domain level metrics for a list of urls\r\n\r\npyscape.py anchor www.example.com anchor.csv -d -f\r\n# export CSV with anchor text phrases pointed at all\r\n# pages on www.example.com\r\n```\r\n\r\n## OSE-style reports\r\n\r\nOften use of the Mozscape API is an extension of working with \r\n[Open Site Explorer](http://www.opensiteexplorer.org/). When then \r\n10,000 lines it provides are insufficient, we can use the command \r\nline to extend the amount of information available. Or, if we're \r\njust trying to pull a lot of reports it will be more convenient to \r\nuse a command line tool. Use the `ose-style` command to generate\r\nreports that match the formatting you would get from OSE.\r\n\r\n## Thanks\r\n\r\nThe [SEOmoz team](http://www.seomoz.org/about/team) deserves a lot \r\nof credit for their work on creating a useful tool. If you're \r\na dev looking for a great place to work, [check them \r\nout](http://www.seomoz.org/about/jobs). And tell them I sent you!\r\n\r\nAlso, preparing all of the data required to set up intelligent \r\ndefaults and provide human-readable output would have been \r\nimpossible without http://jsoneditoronline.com. It's bitchin'.\r\n","google":"UA-40504010-1","note":"Don't delete this file! It's used internally to help with page regeneration."}